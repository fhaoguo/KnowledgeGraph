{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7c856",
   "metadata": {},
   "source": [
    "# 基于wordnet构建英语知识图谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d2cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7bb0c",
   "metadata": {},
   "source": [
    "## 1. 实体和关系抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b649a",
   "metadata": {},
   "source": [
    "### 1.1 Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86b1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_relationship(start, end, rel_type):\n",
    "    '''\n",
    "    索引关系\n",
    "    '''\n",
    "    relationship_index.setdefault(start, {})\n",
    "    relationship_index[start].setdefault(end, {})\n",
    "    relationship_index[start][end] = rel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3b4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_relationship(start, end, rel_type):\n",
    "    '''\n",
    "    添加关系，移除重复关系\n",
    "    '''\n",
    "    if (start in relationship_index and end in relationship_index[start] and rel_type in relationship_index[start][end]) or \\\n",
    "       (end in relationship_index and start in relationship_index[end] and rel_type in relationship_index[end][start]):\n",
    "        pass\n",
    "    else:\n",
    "        index_relationship(start, end, rel_type)\n",
    "        index_relationship(end, start, rel_type)\n",
    "        relationships.append([start, end, rel_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451863b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships(synset):\n",
    "    '''\n",
    "    同义词集实体之间的关系抽取，\n",
    "    '''\n",
    "    # 上位概念（名词，动词）\n",
    "    for related_node in synset.hypernyms():\n",
    "        add_relationship(synset.name(), related_node.name(), 'IsA')\n",
    "    # 下位概念（名词，动词）\n",
    "    for related_node in synset.hyponyms():\n",
    "        add_relationship(related_node.name(), synset.name(), 'IsA')\n",
    "    # 上位整体概念（名词）\n",
    "    for related_node in synset.member_holonyms():\n",
    "        add_relationship(synset.name(), related_node.name(), 'PartOf')\n",
    "    for related_node in synset.substance_holonyms():\n",
    "        add_relationship(synset.name(), related_node.name(), 'PartOf')\n",
    "    for related_node in synset.part_holonyms():\n",
    "        add_relationship(synset.name(), related_node.name(), 'PartOf')\n",
    "    # 下位部件概念（名词）\n",
    "    for related_node in synset.member_meronyms():\n",
    "        add_relationship(related_node.name(), synset.name(), 'PartOf')\n",
    "    for related_node in synset.substance_meronyms():\n",
    "        add_relationship(related_node.name(), synset.name(), 'PartOf')\n",
    "    for related_node in synset.part_meronyms():\n",
    "        add_relationship(related_node.name(), synset.name(), 'PartOf')\n",
    "    # 主题域（名词，动词）\n",
    "    # topic_domains\n",
    "    for related_node in synset.topic_domains():\n",
    "        add_relationship(synset.name(), related_node.name(), 'Domain')\n",
    "    # region_domains\n",
    "    for related_node in synset.region_domains():\n",
    "        add_relationship(synset.name(), related_node.name(), 'Domain')\n",
    "    # usage_domains\n",
    "    for related_node in synset.usage_domains():\n",
    "        add_relationship(synset.name(), related_node.name(), 'Domain')\n",
    "    # 属性\n",
    "    for related_node in synset.attributes():\n",
    "        add_relationship(synset.name(), related_node.name(), 'Attribute')\n",
    "    # 因果\n",
    "    for related_node in synset.causes():\n",
    "        add_relationship(synset.name(), related_node.name(), 'Cause')\n",
    "    # similar_tos\n",
    "    for related_node in synset.similar_tos():\n",
    "        add_relationship(synset.name(), related_node.name(), 'SimilarTo')\n",
    "    # 反义（形容词）\n",
    "    for lemma in synset.lemmas():\n",
    "        for related_node in lemma.antonyms():\n",
    "            add_relationship(synset.name(), related_node.synset().name(), 'Antonym')\n",
    "    # entailment（动词）\n",
    "    for entailment in synset.entailments():\n",
    "        add_relationship(synset.name(), entailment.name(), 'Entailment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59acba",
   "metadata": {},
   "source": [
    "### 1.2 工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538bdb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynsetNode:\n",
    "    '''\n",
    "    同义词集概念节点\n",
    "    '''\n",
    "    def __init__(self, id, pos, definition):\n",
    "        self._label = 'Synset'\n",
    "        self._id = id\n",
    "        self._pos = pos\n",
    "        self._definition = definition\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"SynsetNode({})\".format(self._id)\n",
    "\n",
    "    @property\n",
    "    def get_id(self):\n",
    "        return self._id\n",
    "\n",
    "    @property\n",
    "    def get_pos(self):\n",
    "        return self._pos\n",
    "\n",
    "    @property\n",
    "    def get_definition(self):\n",
    "        return self._definition\n",
    "\n",
    "    @property\n",
    "    def get_label(self):\n",
    "        return self._label\n",
    "\n",
    "    def get_row(self):\n",
    "        return [\n",
    "            self.get_id, self.get_pos, self.get_definition,\n",
    "            self.get_label\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f978ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNode:\n",
    "    '''\n",
    "    词汇节点\n",
    "    '''\n",
    "    def __init__(self, id, name, pos):\n",
    "\n",
    "        self._label = \"Lemma\"\n",
    "        self._id = id\n",
    "        self._name = name\n",
    "        self._pos = pos\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"WordNode({})\".format(self._id)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_header():\n",
    "        return ['id:ID', 'name', 'pos', ':LABEL']\n",
    "\n",
    "    def get_row(self):\n",
    "        return [self._id, self._name, self._pos, self._label]\n",
    "\n",
    "    @property\n",
    "    def get_id(self):\n",
    "        return self._id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc2527",
   "metadata": {},
   "source": [
    "### 1.3 抽取实体和关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f221a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemmas(synset):\n",
    "    '''\n",
    "    抽取词汇实体Lemma(WordNode)\n",
    "    建立Lemma(WordNode)实体和Synset(SynsetNode)实体之间InSynset关系\n",
    "    '''\n",
    "    for lemma in synset.lemmas():\n",
    "        id = ('%s.%s' % (lemma.name().lower(), synset.pos())).lower()\n",
    "        if id not in visited_ids:\n",
    "            visited_ids.add(id)\n",
    "        lemmas.append(WordNode(id, lemma.name().lower(), synset.pos()))\n",
    "        add_relationship(id, synset.name(), 'InSynset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffe4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_index = {}\n",
    "relationships = []  # 关系\n",
    "synsets = []  # 同义词集概念节点构造的实体\n",
    "lemmas = []  # 词汇构造的实体\n",
    "visited_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c991d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synsets = list(nltk.corpus.wordnet.all_synsets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32772caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Synsets extracted\n",
      "10000 Synsets extracted\n",
      "20000 Synsets extracted\n",
      "30000 Synsets extracted\n",
      "40000 Synsets extracted\n",
      "50000 Synsets extracted\n",
      "60000 Synsets extracted\n",
      "70000 Synsets extracted\n",
      "80000 Synsets extracted\n",
      "90000 Synsets extracted\n",
      "100000 Synsets extracted\n",
      "110000 Synsets extracted\n",
      "Extracted lemmas for 0 Synsets\n",
      "Extracted lemmas for 10000 Synsets\n",
      "Extracted lemmas for 20000 Synsets\n",
      "Extracted lemmas for 30000 Synsets\n",
      "Extracted lemmas for 40000 Synsets\n",
      "Extracted lemmas for 50000 Synsets\n",
      "Extracted lemmas for 60000 Synsets\n",
      "Extracted lemmas for 70000 Synsets\n",
      "Extracted lemmas for 80000 Synsets\n",
      "Extracted lemmas for 90000 Synsets\n",
      "Extracted lemmas for 100000 Synsets\n",
      "Extracted lemmas for 110000 Synsets\n"
     ]
    }
   ],
   "source": [
    "for i, synset in enumerate(all_synsets):\n",
    "    # 实体抽取-同义词集概念节点Concept Node\n",
    "    synsets.append(SynsetNode(synset.name(), synset.pos(), synset.definition()))\n",
    "    # 概念关系抽取\n",
    "    extract_relationships(synset)\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i} Synsets extracted')\n",
    "    \n",
    "for i, synset in enumerate(all_synsets):\n",
    "    extract_lemmas(synset)\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Extracted lemmas for {} Synsets\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf63cb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342950, 206978, 117659)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 关系数，词汇实体数，同义词集实体数\n",
    "len(relationships), len(lemmas), len(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9b5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_editor.n.02', 'editor_program.n.01', 'IsA']\n",
      "['dwarf_sperm_whale.n.01', 'toothed_whale.n.01', 'IsA']\n",
      "['thomson.n', 'thomson.n.04', 'InSynset']\n",
      "['chaplainship.n', 'chaplaincy.n.01', 'InSynset']\n",
      "['climacteric.n.01', 'biological_time.n.01', 'IsA']\n",
      "['hilliness.n', 'hilliness.n.01', 'InSynset']\n",
      "['ebony.n', 'ebony.n.02', 'InSynset']\n",
      "['oversimplification.n.02', 'simplification.n.01', 'IsA']\n",
      "['political_correctness.n.01', 'political_incorrectness.n.01', 'Antonym']\n",
      "['forgettable.a.01', 'unmemorable.s.01', 'SimilarTo']\n"
     ]
    }
   ],
   "source": [
    "# 随机输出10个关系\n",
    "import random\n",
    "for i in [random.randint(0, len(relationships)-1) for _ in range(10)]:\n",
    "    print(relationships[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08018b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SynsetNode(hum.v.04)\n",
      "SynsetNode(lox.n.02)\n",
      "SynsetNode(liter.n.01)\n",
      "SynsetNode(fruit_bat.n.01)\n",
      "SynsetNode(noblesse.n.02)\n",
      "SynsetNode(ablaut.n.01)\n",
      "SynsetNode(eastern_chimpanzee.n.01)\n",
      "SynsetNode(cheat.v.03)\n",
      "SynsetNode(labyrinthine_vein.n.01)\n",
      "SynsetNode(bourgogne.n.01)\n"
     ]
    }
   ],
   "source": [
    "# 随机输出10个同义词集概念实体\n",
    "for i in [random.randint(0, len(synsets)-1) for _ in range(10)]:\n",
    "    print(synsets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8da2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordNode(lozal.n)\n",
      "WordNode(theorem.n)\n",
      "WordNode(standing.n)\n",
      "WordNode(rima_glottidis.n)\n",
      "WordNode(neck-deep.s)\n",
      "WordNode(lentibulariaceae.n)\n",
      "WordNode(repent.v)\n",
      "WordNode(militarized.s)\n",
      "WordNode(comatulid.n)\n",
      "WordNode(habitation.n)\n"
     ]
    }
   ],
   "source": [
    "# 随机输出10个词汇实体\n",
    "for i in [random.randint(0, len(lemmas)-1) for _ in range(10)]:\n",
    "    print(lemmas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df400a",
   "metadata": {},
   "source": [
    "## 2. 关系存储为CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce410a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e55118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing synsets...Done\n"
     ]
    }
   ],
   "source": [
    "print('Writing synsets...', end='')\n",
    "with open('synsets.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id:ID', 'pos:string', 'definition:string', ':LABEL'])\n",
    "    for synset in synsets:\n",
    "        writer.writerow(synset.get_row())\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c16efb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing words...Done\n"
     ]
    }
   ],
   "source": [
    "print('Writing words...', end='')\n",
    "with open('words.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(WordNode.get_header())\n",
    "    for word in lemmas:\n",
    "        writer.writerow(word.get_row())\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dc0ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing relationships...Done\n"
     ]
    }
   ],
   "source": [
    "print('Writing relationships...', end='')\n",
    "with open('relationships.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([':START_ID', ':END_ID', ':TYPE'])\n",
    "    for relationship in relationships:\n",
    "        writer.writerow(relationship)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "413a5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8572b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id:ID</th>\n",
       "      <th>pos:string</th>\n",
       "      <th>definition:string</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able.a.01</td>\n",
       "      <td>a</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable.a.01</td>\n",
       "      <td>a</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaxial.a.01</td>\n",
       "      <td>a</td>\n",
       "      <td>facing away from the axis of an organ or organism</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaxial.a.01</td>\n",
       "      <td>a</td>\n",
       "      <td>nearest to or facing toward the axis of an org...</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acroscopic.a.01</td>\n",
       "      <td>a</td>\n",
       "      <td>facing or on the side toward the apex</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117654</th>\n",
       "      <td>run_dry.v.01</td>\n",
       "      <td>v</td>\n",
       "      <td>become empty of water</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117655</th>\n",
       "      <td>fog_up.v.01</td>\n",
       "      <td>v</td>\n",
       "      <td>get foggy</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117656</th>\n",
       "      <td>char.v.01</td>\n",
       "      <td>v</td>\n",
       "      <td>burn to charcoal</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117657</th>\n",
       "      <td>haze.v.01</td>\n",
       "      <td>v</td>\n",
       "      <td>become hazy, dull, or cloudy</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117658</th>\n",
       "      <td>deflagrate.v.01</td>\n",
       "      <td>v</td>\n",
       "      <td>cause to burn rapidly and with great intensity</td>\n",
       "      <td>Synset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id:ID pos:string  \\\n",
       "0             able.a.01          a   \n",
       "1           unable.a.01          a   \n",
       "2          abaxial.a.01          a   \n",
       "3          adaxial.a.01          a   \n",
       "4       acroscopic.a.01          a   \n",
       "...                 ...        ...   \n",
       "117654     run_dry.v.01          v   \n",
       "117655      fog_up.v.01          v   \n",
       "117656        char.v.01          v   \n",
       "117657        haze.v.01          v   \n",
       "117658  deflagrate.v.01          v   \n",
       "\n",
       "                                        definition:string  :LABEL  \n",
       "0       (usually followed by `to') having the necessar...  Synset  \n",
       "1       (usually followed by `to') not having the nece...  Synset  \n",
       "2       facing away from the axis of an organ or organism  Synset  \n",
       "3       nearest to or facing toward the axis of an org...  Synset  \n",
       "4                   facing or on the side toward the apex  Synset  \n",
       "...                                                   ...     ...  \n",
       "117654                              become empty of water  Synset  \n",
       "117655                                          get foggy  Synset  \n",
       "117656                                   burn to charcoal  Synset  \n",
       "117657                       become hazy, dull, or cloudy  Synset  \n",
       "117658     cause to burn rapidly and with great intensity  Synset  \n",
       "\n",
       "[117659 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('synsets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1117b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id:ID</th>\n",
       "      <th>name</th>\n",
       "      <th>pos</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able.a</td>\n",
       "      <td>able</td>\n",
       "      <td>a</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable.a</td>\n",
       "      <td>unable</td>\n",
       "      <td>a</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaxial.a</td>\n",
       "      <td>abaxial</td>\n",
       "      <td>a</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dorsal.a</td>\n",
       "      <td>dorsal</td>\n",
       "      <td>a</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaxial.a</td>\n",
       "      <td>adaxial</td>\n",
       "      <td>a</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206973</th>\n",
       "      <td>fog_up.v</td>\n",
       "      <td>fog_up</td>\n",
       "      <td>v</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206974</th>\n",
       "      <td>char.v</td>\n",
       "      <td>char</td>\n",
       "      <td>v</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206975</th>\n",
       "      <td>coal.v</td>\n",
       "      <td>coal</td>\n",
       "      <td>v</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206976</th>\n",
       "      <td>haze.v</td>\n",
       "      <td>haze</td>\n",
       "      <td>v</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206977</th>\n",
       "      <td>deflagrate.v</td>\n",
       "      <td>deflagrate</td>\n",
       "      <td>v</td>\n",
       "      <td>Lemma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206978 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id:ID        name pos :LABEL\n",
       "0             able.a        able   a  Lemma\n",
       "1           unable.a      unable   a  Lemma\n",
       "2          abaxial.a     abaxial   a  Lemma\n",
       "3           dorsal.a      dorsal   a  Lemma\n",
       "4          adaxial.a     adaxial   a  Lemma\n",
       "...              ...         ...  ..    ...\n",
       "206973      fog_up.v      fog_up   v  Lemma\n",
       "206974        char.v        char   v  Lemma\n",
       "206975        coal.v        coal   v  Lemma\n",
       "206976        haze.v        haze   v  Lemma\n",
       "206977  deflagrate.v  deflagrate   v  Lemma\n",
       "\n",
       "[206978 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6554236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able.a.01</td>\n",
       "      <td>ability.n.01</td>\n",
       "      <td>Attribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able.a.01</td>\n",
       "      <td>ability.n.02</td>\n",
       "      <td>Attribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>able.a.01</td>\n",
       "      <td>unable.a.01</td>\n",
       "      <td>Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable.a.01</td>\n",
       "      <td>ability.n.01</td>\n",
       "      <td>Attribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaxial.a.01</td>\n",
       "      <td>biology.n.01</td>\n",
       "      <td>Domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342945</th>\n",
       "      <td>fog_up.v</td>\n",
       "      <td>fog_up.v.01</td>\n",
       "      <td>InSynset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342946</th>\n",
       "      <td>char.v</td>\n",
       "      <td>char.v.01</td>\n",
       "      <td>InSynset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342947</th>\n",
       "      <td>coal.v</td>\n",
       "      <td>char.v.01</td>\n",
       "      <td>InSynset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342948</th>\n",
       "      <td>haze.v</td>\n",
       "      <td>haze.v.01</td>\n",
       "      <td>InSynset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342949</th>\n",
       "      <td>deflagrate.v</td>\n",
       "      <td>deflagrate.v.01</td>\n",
       "      <td>InSynset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           :START_ID          :END_ID      :TYPE\n",
       "0          able.a.01     ability.n.01  Attribute\n",
       "1          able.a.01     ability.n.02  Attribute\n",
       "2          able.a.01      unable.a.01    Antonym\n",
       "3        unable.a.01     ability.n.01  Attribute\n",
       "4       abaxial.a.01     biology.n.01     Domain\n",
       "...              ...              ...        ...\n",
       "342945      fog_up.v      fog_up.v.01   InSynset\n",
       "342946        char.v        char.v.01   InSynset\n",
       "342947        coal.v        char.v.01   InSynset\n",
       "342948        haze.v        haze.v.01   InSynset\n",
       "342949  deflagrate.v  deflagrate.v.01   InSynset\n",
       "\n",
       "[342950 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('relationships.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272238fd",
   "metadata": {},
   "source": [
    "## 3. CSV导入Neo4j(ONgDB)及可视化效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfafdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入的时候需要把neo4j停掉, 而且删掉原来的数据库\n",
    "# bin/ongdb-admin import --database graph.db --nodes=import/synsets.csv --nodes=import/words.csv --relationships=import/relationships.csv --ignore-duplicate-nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b9018",
   "metadata": {},
   "source": [
    "### 可视化效果\n",
    "![](./graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c05ea",
   "metadata": {},
   "source": [
    "## 4. 简单的问答应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c306cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship, NodeMatcher, RelationshipMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10af5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_inference(wordnet_graph, question):\n",
    "    n_matcher = NodeMatcher(wordnet_graph)\n",
    "    r_matcher = RelationshipMatcher(wordnet_graph)\n",
    "\n",
    "    word = question.split(\" \")[-1]\n",
    "    print(\"Find knowledge for {}......\\n\\n\".format(word))\n",
    "    entity_node = n_matcher.match(\"Lemma\", name=word).first()\n",
    "\n",
    "    for r in r_matcher.match([entity_node], r_type=\"InSynset\"):\n",
    "        concept_node = r.end_node\n",
    "        print(\"Definition: \\n\")\n",
    "        print(\"-- {} is {}\".format(word, concept_node[\"definition\"]))\n",
    "        print(\"\\n\" + \"*\" * 50 + \"\\n\")\n",
    "\n",
    "        print(\"Part of relations\")\n",
    "        for isa_r in r_matcher.match([concept_node], r_type=\"PartOf\"):\n",
    "            end = isa_r.end_node\n",
    "            for isa_r in r_matcher.match([None, end], r_type=\"InSynset\"):\n",
    "                start = isa_r.start_node\n",
    "                print(\"-- {} is part of {}\".format(word, start[\"name\"]))\n",
    "            break\n",
    "\n",
    "        for isa_r in r_matcher.match([None, concept_node], r_type=\"PartOf\"):\n",
    "            end = isa_r.end_node\n",
    "            for isa_r in r_matcher.match([None, end], r_type=\"InSynset\"):\n",
    "                start = isa_r.start_node\n",
    "                print(\"-- {} is part of {}\".format(start[\"name\"], word))\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"*\" * 50 + \"\\n\")\n",
    "\n",
    "        print(\"For examples: \\n\")\n",
    "        for i, isa_r in enumerate(\n",
    "                r_matcher.match([None, concept_node], r_type=\"IsA\")):\n",
    "            start = isa_r.start_node\n",
    "            print(\"{}. {} is a {} which means {}\\n\".format(\n",
    "                i + 1, start['id'].split(\".\")[0], word, start[\"definition\"]))\n",
    "        print(\"\\n\" + \"*\" * 50 + \"\\n\")\n",
    "\n",
    "        print(\"Similar Things: \\n\")\n",
    "        for i, isa_r in enumerate(\n",
    "                r_matcher.match([concept_node], r_type=\"SimilarTo\")):\n",
    "            end = isa_r.end_node\n",
    "            print(\"{}\".format(end[\"id\"].split(\".\")[0]))\n",
    "\n",
    "        for i, isa_r in enumerate(\n",
    "                r_matcher.match([None, concept_node], r_type=\"SimilarTo\")):\n",
    "            start = isa_r.start_node\n",
    "            print(\"{}\".format(start[\"id\"].split(\".\")[0]))\n",
    "\n",
    "        print(\"\\n\" + \"*\" * 50 + \"\\n\")\n",
    "\n",
    "        print(\"Same domain words: \\n\")\n",
    "        for i, isa_r in enumerate(\n",
    "                r_matcher.match([concept_node], r_type=\"Domain\")):\n",
    "            end = isa_r.end_node\n",
    "            print(\"{}\".format(end[\"id\"].split(\".\")[0]))\n",
    "\n",
    "        for i, isa_r in enumerate(\n",
    "                r_matcher.match([None, concept_node], r_type=\"Domain\")):\n",
    "            start = isa_r.start_node\n",
    "            print(\"{}\".format(start[\"id\"].split(\".\")[0]))\n",
    "\n",
    "        print(\"\\n\" + \"*\" * 50 + \"\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8185ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"http://localhost:7474\"\n",
    "user = \"ongdb\"\n",
    "password = \"123456\"\n",
    "wordnet_graph = Graph(uri=uri, user=user, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f448501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find knowledge for computer......\n",
      "\n",
      "\n",
      "Definition: \n",
      "\n",
      "-- computer is a machine for performing calculations automatically\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Part of relations\n",
      "-- computer is part of platform\n",
      "-- information_processing_system is part of computer\n",
      "-- electronic_computer is part of computer\n",
      "-- data_processor is part of computer\n",
      "-- computing_device is part of computer\n",
      "-- computing_machine is part of computer\n",
      "-- computer is part of computer\n",
      "\n",
      "**************************************************\n",
      "\n",
      "For examples: \n",
      "\n",
      "1. web_site is a computer which means a computer connected to the internet that maintains a series of web pages on the World Wide Web\n",
      "\n",
      "2. turing_machine is a computer which means a hypothetical computer with an infinitely long memory tape\n",
      "\n",
      "3. server is a computer which means (computer science) a computer that provides client stations with access to files and printers as shared resources to a computer network\n",
      "\n",
      "4. predictor is a computer which means a computer for controlling antiaircraft fire that computes the position of an aircraft at the instant of a shell's arrival\n",
      "\n",
      "5. pari-mutuel_machine is a computer which means computer that registers bets and divides the total amount bet among those who won\n",
      "\n",
      "6. number_cruncher is a computer which means a computer capable of performing a large number of mathematical operations per second\n",
      "\n",
      "7. node is a computer which means (computer science) any computer that is hooked up to a computer network\n",
      "\n",
      "8. home_computer is a computer which means a computer intended for use in the home\n",
      "\n",
      "9. digital_computer is a computer which means a computer that represents information by numerical (binary) digits\n",
      "\n",
      "10. analog_computer is a computer which means a computer that represents information by variable quantities (e.g., positions or voltages)\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Similar Things: \n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Same domain words: \n",
      "\n",
      "computer_science\n",
      "outage\n",
      "pass\n",
      "format\n",
      "digital_communication\n",
      "beta_test\n",
      "alpha_test\n",
      "data_structure\n",
      "visual_display_unit\n",
      "throughput\n",
      "slot\n",
      "scratchpad\n",
      "plotter\n",
      "module\n",
      "faceplate\n",
      "console\n",
      "back_up\n",
      "interconnection\n",
      "up\n",
      "incompatible\n",
      "compatible\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"what is computer\"\n",
    "knowledge_inference(wordnet_graph, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bae47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find knowledge for us......\n",
      "\n",
      "\n",
      "Definition: \n",
      "\n",
      "-- us is North American republic containing 50 states - 48 conterminous states in North America plus Alaska in northwest North America and the Hawaiian Islands in the Pacific Ocean; achieved independence in 1776\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Part of relations\n",
      "-- us is part of north_america\n",
      "-- u.s.a. is part of us\n",
      "-- usa is part of us\n",
      "-- u.s. is part of us\n",
      "-- us is part of us\n",
      "-- the_states is part of us\n",
      "-- america is part of us\n",
      "-- united_states_of_america is part of us\n",
      "-- united_states is part of us\n",
      "\n",
      "**************************************************\n",
      "\n",
      "For examples: \n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Similar Things: \n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Same domain words: \n",
      "\n",
      "billionth\n",
      "octillion\n",
      "septillion\n",
      "sextillion\n",
      "quintillion\n",
      "quadrillion\n",
      "trillion\n",
      "billion\n",
      "inch\n",
      "dollar\n",
      "discount_rate\n",
      "golden_fern\n",
      "hedeoma\n",
      "ringworm_bush\n",
      "pineapple_weed\n",
      "genus_epiphyllum\n",
      "gibson\n",
      "yankee\n",
      "staff_member\n",
      "old_man\n",
      "mestizo\n",
      "mestiza\n",
      "desperado\n",
      "paleface\n",
      "marlowe\n",
      "union\n",
      "marshall_islands\n",
      "barrio\n",
      "county\n",
      "intelligence_community\n",
      "independent_agency\n",
      "nation\n",
      "tribe\n",
      "federal_department\n",
      "state_department\n",
      "combination_in_restraint_of_trade\n",
      "cola\n",
      "partridge\n",
      "teacake\n",
      "tart\n",
      "inaugural_address\n",
      "athapaskan\n",
      "bill_of_rights\n",
      "joint_resolution\n",
      "social_security_number\n",
      "shamanism\n",
      "southernism\n",
      "beak\n",
      "totem\n",
      "slave_market\n",
      "maquiladora\n",
      "water_spaniel\n",
      "american_civil_war\n",
      "recall\n",
      "boston_tea_party\n",
      "trust_busting\n",
      "reallotment\n",
      "snake_dance\n",
      "multiple_voting\n",
      "marine\n",
      "trillion\n",
      "billion\n",
      "presidents'_day\n",
      "washington's_birthday\n",
      "lincoln's_birthday\n",
      "groundhog_day\n",
      "freshman\n",
      "trapezoid\n",
      "trapezium\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"what is us\"\n",
    "knowledge_inference(wordnet_graph, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132081e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
